# app/main.py â€” stat-explainer (Trimmed: Upload/Preview + RAG + OGA-HDiC, Level 3)
# -------------------------------------------------------------
# åŠŸèƒ½ï¼š
# 1) ä¸Šå‚³èˆ‡é è¦½ Upload & Previewï¼ˆcsv/json/pklï¼‰
# 2) RAG å¢å¼·ï¼šä¸Šå‚³ .txt å»ºç´¢å¼• â†’ è¼”åŠ© GPT è§£é‡‹
# 3) è‡ªè¨‚å‡½å¼ï¼šOGA-HDiCï¼ˆé¸ y æ¬„ + åƒæ•¸ï¼‰Level 3 æ¨¡å¼
#   - åƒ…æœ¬åœ°åŸ·è¡Œå‡½å¼ï¼Œä¸å°‡åŸå§‹è³‡æ–™å‚³çµ¦ LLM
#   - è‹¥éœ€è¦ LLMï¼Œåªæœƒå‚³é€ç²¾ç°¡å¾Œçµæœæ‘˜è¦
# -------------------------------------------------------------

import json
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import pandas as pd
import streamlit as st

# æª”æ¡ˆè™•ç†
from core.file_handler import read_uploaded_file, save_uploaded_file  # type: ignore
from core.llm_tools import *

# ç¢ºä¿å¯ä»¥ import core/


# RAG ç®¡ç·š
try:
    from core.rag_chain import run_rag_pipeline  # type: ignore
except Exception:  # noqa: BLE001
    run_rag_pipeline = None

# å·¥å…·å‘¼å«
from core.llm_executor import make_client  # type: ignore
from core.tool_registry import dispatch_tool  # type: ignore


# -------------------------------------------------------------
# åŸºæœ¬è¨­å®š
# -------------------------------------------------------------
def to_jsonable(obj, max_list=100, max_str=4000):
    """æŠŠ numpy/pandas/statsmodels çµæ§‹è½‰æˆå¯ JSON åºåˆ—åŒ–çš„ç´” Pythonã€‚
    æœƒå°é•·åºåˆ—/å­—ä¸²åšæˆªæ–·ï¼Œé¿å… payload éå¤§ã€‚"""
    # åŸºæœ¬å‹åˆ¥
    if obj is None or isinstance(obj, (bool, int, float, str)):
        if isinstance(obj, str) and len(obj) > max_str:
            return obj[:max_str] + " ...<truncated>"
        return obj

    # numpy æ¨™é‡
    if isinstance(obj, (np.integer, np.floating)):
        return obj.item()

    # pandas
    if isinstance(obj, pd.Series):
        lst = obj.tolist()
        if len(lst) > max_list:
            return lst[:max_list] + ["<truncated>"]
        return lst
    if isinstance(obj, pd.Index):
        lst = obj.tolist()
        if len(lst) > max_list:
            return lst[:max_list] + ["<truncated>"]
        return lst
    if isinstance(obj, pd.DataFrame):
        # åªè¼¸å‡ºå‰ max_list åˆ—
        df_small = obj.head(max_list)
        return {
            "columns": df_small.columns.tolist(),
            "rows": df_small.to_dict(orient="records"),
            "note": f"truncated to {len(df_small)} rows" if len(obj) > max_list else "full",
        }

    # numpy é™£åˆ—/åºåˆ—
    if isinstance(obj, (list, tuple, set)):
        lst = list(obj)
        if len(lst) > max_list:
            lst = lst[:max_list] + ["<truncated>"]
        return [to_jsonable(v, max_list=max_list, max_str=max_str) for v in lst]
    if isinstance(obj, np.ndarray):
        lst = obj.tolist()
        if len(lst) > max_list:
            lst = lst[:max_list] + ["<truncated>"]
        return lst

    # dict
    if isinstance(obj, dict):
        out = {}
        for k, v in obj.items():
            out[str(k)] = to_jsonable(v, max_list=max_list, max_str=max_str)
        return out

    # statsmodels ç­‰å…¶ä»–è¤‡é›œç‰©ä»¶ â†’ å˜—è©¦æŠ“å¸¸ç”¨å±¬æ€§ï¼Œå¦å‰‡è½‰å­—ä¸²
    for attr in ("params", "pvalues", "rsquared", "aic", "bic", "bic_llf", "llf"):
        if hasattr(obj, attr):
            try:
                return to_jsonable(getattr(obj, attr), max_list=max_list, max_str=max_str)
            except Exception:
                pass

    return str(obj)[:max_str] + (" ...<truncated>" if len(str(obj)) > max_str else "")


st.set_page_config(page_title="Stat Explainer", layout="wide")
st.title("ğŸ“Š stat-explainer â€” ä¸Šå‚³/é è¦½ + RAG + OGA-HDiC (Level 3)")


# å–å¾— API Key
def get_api_key() -> str | None:
    return st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))


API_KEY = get_api_key()
if not API_KEY:
    st.warning("æœªæ‰¾åˆ° OPENAI_API_KEYï¼ˆSecrets æˆ–ç’°å¢ƒè®Šæ•¸ï¼‰ï¼ŒRAG åŠŸèƒ½å°‡ç„¡æ³•å‘¼å« GPTã€‚")

# =============================================================
# 1) ä¸Šå‚³èˆ‡é è¦½
# =============================================================
st.header("1) ä¸Šå‚³èˆ‡é è¦½ Upload & Preview")

uploaded_file = st.file_uploader(
    "è«‹ä¸Šå‚³è³‡æ–™/æ¨¡å‹è¼¸å‡ºæª”ï¼ˆcsv / json / pklï¼‰",
    type=["csv", "json", "pkl"],
    key="data_file",
)
preview: pd.DataFrame | None = None
file_path: str | None = None

if uploaded_file:
    file_path = save_uploaded_file(uploaded_file)
    st.success(f"âœ… å·²å„²å­˜è‡³: {file_path}")
    preview = read_uploaded_file(file_path)
    st.subheader("ğŸ“‹ æª”æ¡ˆé è¦½")
    if isinstance(preview, pd.DataFrame):
        st.dataframe(preview, use_container_width=True)
        st.caption(f"Rows: {preview.shape[0]} | Cols: {preview.shape[1]}")
    else:
        st.write(preview)

# # =============================================================
# # 2) RAG å¢å¼·ï¼ˆ.txt èƒŒæ™¯ï¼‰
# # =============================================================
# st.header("2) RAG å¢å¼·ï¼ˆä¸Šå‚³ .txt èƒŒæ™¯ â†’ æª¢ç´¢ + è§£é‡‹)")

# rag_file = st.file_uploader("ä¸Šå‚³èƒŒæ™¯èªªæ˜æª”ï¼ˆç´”æ–‡å­— .txtï¼‰", type=["txt"], key="rag_file")
# rag_text: str | None = None
# if rag_file is not None:
#     try:
#         rag_text = rag_file.read().decode("utf-8", errors="ignore")
#     except Exception:  # noqa: BLE001
#         rag_text = None

# if rag_text:
#     st.text_area("ğŸ“ èƒŒæ™¯å…§å®¹é è¦½", rag_text[:5000], height=180)

# if st.button("ğŸ“– ä½¿ç”¨ RAG è§£é‡‹", disabled=(rag_text is None or preview is None)):
#     if not API_KEY:
#         st.error("ç¼ºå°‘ OPENAI_API_KEYï¼Œç„¡æ³•åŸ·è¡Œ RAGã€‚")
#     elif run_rag_pipeline is None:
#         st.error("æœªç™¼ç¾ core.rag_chain.run_rag_pipelineã€‚")
#     else:
#         try:
#             question = "è«‹æ ¹æ“šèƒŒæ™¯èªªæ˜èˆ‡ä¸Šå‚³è³‡æ–™ï¼Œè§£é‡‹é€™ä»½æ¨¡å‹/è³‡æ–™çš„é‡é»èˆ‡çµè«–ã€‚"
#             response = run_rag_pipeline(question=question, raw_text=rag_text)  # type: ignore[arg-type]
#             st.text_area("ğŸ” GPTï¼ˆRAGï¼‰å›æ‡‰", value=response, height=320)
#         except Exception as e:
#             st.error(f"RAG åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")

# =============================================================
# 3) è‡ªè¨‚å‡½å¼ï¼šOGA-HDiCï¼ˆLevel 3 æœ¬åœ° + å¯é¸ LLM æ‘˜è¦ï¼‰
# =============================================================
st.header("3) è‡ªè¨‚å‡½å¼ï¼šOGA-HDiCï¼ˆé¸æ“‡ y æ¬„ + åƒæ•¸ï¼‰")

if preview is None or not isinstance(preview, pd.DataFrame):
    st.info("è«‹å…ˆæ–¼ä¸Šæ–¹ä¸Šå‚³è³‡æ–™æª”æ¡ˆï¼ˆcsv/json/pklï¼‰ã€‚")
else:
    df = preview
    cols = list(df.columns)
    if not cols:
        st.warning("è³‡æ–™æ²’æœ‰æ¬„ä½å¯ä¾›é¸æ“‡ã€‚")
    else:
        y_col = st.selectbox("é¸æ“‡ç›®æ¨™è®Šæ•¸ y æ¬„ä½", options=cols, index=0)
        default_x = [c for c in cols if c != y_col]
        x_cols = st.multiselect(
            "é¸æ“‡ç‰¹å¾µæ¬„ä½ Xï¼ˆé è¨­ç‚º y ä»¥å¤–å…¨éƒ¨ï¼‰",
            options=cols,
            default=default_x,
        )

        with st.expander("åƒæ•¸è¨­å®š", expanded=False):
            Kn = st.number_input("Knï¼ˆ0=ä¸æŒ‡å®šï¼‰", value=0, min_value=0, step=1)
            c1 = st.number_input("c1", value=5.0, step=0.5)
            HDIC_Type = st.selectbox("HDIC_Type", options=["HDBIC", "HDHQ", "HDAIC"], index=0)
            c2 = st.number_input("c2", value=2.0, step=0.5)
            c3 = st.number_input("c3", value=2.01, step=0.01)
            intercept = st.checkbox("intercept", value=True)

        # ---- æœ¬åœ°åŸ·è¡Œï¼ˆä¸å°‡åŸå§‹è³‡æ–™é€ LLMï¼‰----
        st.caption("ğŸ’¡ Level 3ï¼šåªåœ¨æœ¬åœ°åŸ·è¡Œ OGA-HDiCï¼Œè‹¥è¦ LLM æ‘˜è¦ï¼Œåªå‚³é€ç²¾ç°¡çµæœã€‚")

        use_cols = [y_col] + x_cols if x_cols else [y_col]
        sub_df = df[use_cols].copy()
        sub_df = sub_df.apply(pd.to_numeric, errors="ignore")
        data_records_local = sub_df.to_dict(orient="records")

        Kn_arg = None if Kn == 0 else int(Kn)
        tool_args = {
            "data": data_records_local,
            "y_col": y_col,
            "x_cols": x_cols,
            "Kn": Kn_arg,
            "c1": c1,
            "HDIC_Type": HDIC_Type,
            "c2": c2,
            "c3": c3,
            "intercept": intercept,
        }

        col1, col2 = st.columns([1, 1])
        with col1:
            run_local = st.button("âš™ï¸ åƒ…æœ¬åœ°åŸ·è¡Œ OGA-HDiC")
        with col2:
            run_local_summary = st.button("ğŸ“ æœ¬åœ°åŸ·è¡Œ + LLM æ‘˜è¦")

        if run_local:
            try:
                result = dispatch_tool("run_oga_hdic", tool_args)
                st.success("âœ… æœ¬åœ° OGA-HDiC å®Œæˆã€‚")
                with st.expander("ğŸ”§ æœ¬åœ°çµæœ JSON"):
                    st.json(result)
            except Exception as e:
                st.error(f"OGA-HDiC æœ¬åœ°åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        summary_model = st.selectbox(
            "é¸æ“‡ LLM æ¨¡å‹ï¼ˆæ‘˜è¦ç”¨ï¼‰", ["gpt-4o-mini", "gpt-4o"], index=0, key="oga_summary_model"
        )
        if run_local_summary:
            try:
                result = dispatch_tool("run_oga_hdic", tool_args)
                st.success("âœ… æœ¬åœ° OGA-HDiC å®Œæˆï¼Œæº–å‚™è«‹ LLM æ‘˜è¦â€¦")
                with st.expander("ğŸ”§ æœ¬åœ°çµæœ JSON"):
                    st.json(result)

                if not API_KEY:
                    st.warning("æœªè¨­å®š OPENAI_API_KEYï¼Œè·³é LLM æ‘˜è¦ã€‚")
                else:
                    client = make_client(API_KEY)

                    # 1) å…ˆéæ¿¾å¤§å‹æ¬„ä½
                    filtered = dict(result)
                    for k in [
                        "X",
                        "y",
                        "coef_matrix",
                        "residuals",
                        "fitted_values",
                        "influence",
                        "cov_params",
                    ]:
                        if k in filtered:
                            filtered[k] = "<omitted>"

                    # 2) è½‰ç‚º JSON-safeï¼ˆè§£æ±º numpy/pandas/ResultWrapper ç­‰å‹åˆ¥ï¼‰
                    safe = to_jsonable(filtered, max_list=100, max_str=4000)

                    # 3) åºåˆ—åŒ–ï¼ˆseparators å»ç©ºç™½ï¼Œæ¸› tokenï¼‰
                    payload = json.dumps(safe, ensure_ascii=False, separators=(",", ":"))

                    summary = (
                        client.chat.completions.create(
                            model=summary_model,
                            messages=[
                                {
                                    "role": "system",
                                    "content": "ä½ æ˜¯çµ±è¨ˆåŠ©ç†ï¼Œè«‹ä»¥ç¹é«”ä¸­æ–‡æ‘˜è¦ç ”ç©¶çµæœã€‚",
                                },
                                {
                                    "role": "user",
                                    "content": "ä»¥ä¸‹æ˜¯ OGA-HDiC çš„çµæœï¼Œ'J_Trim'æ˜¯é¸åˆ°çš„é‡è¦è®Šæ•¸ï¼Œè«‹æ•´ç†è¦é»ï¼šé¸åˆ°çš„è®Šæ•¸ã€é—œéµæŒ‡æ¨™èˆ‡å»ºè­°ã€‚",
                                },
                                {"role": "user", "content": payload},
                            ],
                            temperature=0.2,
                        )
                        .choices[0]
                        .message.content
                    )

                    st.subheader("ğŸ“ LLM æ‘˜è¦")
                    st.write(summary)

            except Exception as e:
                st.error(f"OGA-HDiC åŸ·è¡Œæˆ– LLM æ‘˜è¦éŒ¯èª¤ï¼š{e}")

# -------------------------------------------------------------
# End of file
# -------------------------------------------------------------
