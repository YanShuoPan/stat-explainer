# app/main.py å…§åˆé©ä½ç½®åŠ å…¥ï¼ˆç¢ºä¿èƒ½ import core/*ï¼‰
import os
import json
import streamlit as st

# è‹¥ä½ éœ€è¦ï¼šæŠŠå°ˆæ¡ˆæ ¹ç›®éŒ„åŠ åˆ° sys.pathï¼ˆä½ ä¹‹å‰å·²åŠ éå¯ç•¥ï¼‰
# import sys, os
# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from core.tool_registry import register_tool
from core.llm_executor import make_client, chat_with_tools

# ====== 1) è¨»å†Šä½ çš„å·¥å…·ï¼ˆç¤ºç¯„ï¼šæœ€å°æ•¸å­¸æ¨¡å‹ï¼‰ ======
@register_tool(
    name="my_model",
    description="è¨ˆç®—æœ€å°æ•¸å­¸æ¨¡å‹ï¼šx^2 + y",
    schema={
        "type": "object",
        "properties": {
            "x": {"type": "number", "description": "æ•¸å­— x"},
            "y": {"type": "number", "description": "æ•¸å­— y"},
        },
        "required": ["x", "y"],
    },
)
def my_model(args: dict):
    x = float(args["x"])
    y = float(args["y"])
    return {"result": x ** 2 + y}

# ====== 2) UIï¼šå¿«é€Ÿæ¸¬è©¦å·¥å…·å‘¼å« ======
st.divider()
st.header("ğŸ§ª LLM å·¥å…·å‘¼å«ï¼ˆFunction Callingï¼‰æ¨¡çµ„åŒ–æ¸¬è©¦")

col1, col2 = st.columns(2)
with col1:
    x_val = st.number_input("x", value=3.0, step=1.0)
with col2:
    y_val = st.number_input("y", value=5.0, step=1.0)

question = st.text_input(
    "ä½ çš„å•é¡Œ",
    "è«‹ç”¨å¯ç”¨çš„å·¥å…·è¨ˆç®—ç•¶ x=3, y=5 æ™‚çš„æ¨¡å‹è¼¸å‡ºï¼Œä¸¦ç°¡è¦èªªæ˜ã€‚"
)

model_name = st.selectbox("é¸æ“‡æ¨¡å‹", ["gpt-4o-mini", "gpt-4o"], index=0)

if st.button("ğŸš€ åŸ·è¡Œå·¥å…·æ¸¬è©¦"):
    # è®€å– API Keyï¼šCloud ç”¨ st.secretsï¼Œæœ¬åœ°ç”¨ .env / ç’°å¢ƒè®Šæ•¸
    api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
    if not api_key:
        st.error("æ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè«‹åœ¨ Streamlit Secrets æˆ–ç’°å¢ƒè®Šæ•¸ä¸­è¨­å®šã€‚")
    else:
        try:
            client = make_client(api_key)
            messages = [
                {"role": "system", "content": "ä½ æ˜¯æ“…é•·çµ±è¨ˆå»ºæ¨¡èˆ‡æ•¸å€¼é‹ç®—çš„åŠ©ç†ã€‚"},
                {"role": "user", "content": question},
                # æŠŠæ•¸å€¼ä¹Ÿæä¾›çµ¦ LLMï¼Œè®“å®ƒæ›´å®¹æ˜“æ±ºå®šå·¥å…·åƒæ•¸
                {"role": "user", "content": f"çµ¦å®š x={x_val}, y={y_val}"},
                {"role": "user", "content": "è‹¥éœ€è¦è¨ˆç®—ï¼Œè«‹å‘¼å« my_model ä¸¦å‚³å…¥åƒæ•¸ã€‚"},
            ]
            out = chat_with_tools(client, messages, model=model_name, temperature=0.2)

            st.success("LLM æœ€çµ‚å›è¦†ï¼š")
            st.write(out["content"])
            with st.expander("ğŸ”§ å·¥å…·å‘¼å«æ˜ç´°ï¼ˆdebugï¼‰"):
                st.json(out["tool_results"])
        except Exception as e:
            st.error(f"åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
